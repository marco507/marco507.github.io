{"id":557,"date":"2023-10-25T11:56:44","date_gmt":"2023-10-25T09:56:44","guid":{"rendered":"https:\/\/bigdatatime.eu\/?p=557"},"modified":"2023-11-03T09:37:10","modified_gmt":"2023-11-03T08:37:10","slug":"building-a-private-ai-tutor-for-a-microsoft-learn-course","status":"publish","type":"post","link":"https:\/\/bigdatatime.eu\/building-a-private-ai-tutor-for-a-microsoft-learn-course\/","title":{"rendered":"Building a Private AI Tutor for a Microsoft Learn Course"},"content":{"rendered":"<p>In this article, we will look into one of my recent projects, which is the creation of a specialized private AI tutor for a Microsoft Learn course for the <a href=\"https:\/\/learn.microsoft.com\/de-de\/credentials\/certifications\/power-bi-data-analyst-associate\/\" target=\"_blank\" rel=\"noopener\">Power BI certification<\/a>. Given the results of the job market analysis discussed in my most recent <a href=\"https:\/\/bigdatatime.eu\/discovering-in-demand-skills-and-salary-ranges-in-austrias-data-science-job-market\/\" target=\"_blank\" rel=\"noopener\">article<\/a> and the fact that I already wanted to refresh my Power BI knowledge, this is the perfect opportunity for this project.\u00a0 The overall aim was to provide an interface where users could ask questions and receive accurate and relevant responses based on the content of the course. We will now look into the details of the implementation.<\/p>\n<h2>Data Collection<\/h2>\n<p>To build the knowledge base for our AI tutor, we will utilize Python along with libraries like Selenium and BeautifulSoup to scrape all necessary information from the web. By converting each section of the course into individual text files, we can create a comprehensive database to serve as our tutor&#8217;s knowledge repository. Thereby, we have to utilize Selenium, which allows us to retrieve HTML code that is dynamically generated by JavaScript. We basically retrieve the raw HTML of each page and extract the actual content with the help of BeautifulSoup. Following, we clean the data by removing links to quizzes and interactive exercises in the course and splitting up the raw text into individual chapters by using the heading structure of the HTML.<\/p>\n<p>This follows the same logic as the PDF conversion pipeline that was used for the <a href=\"https:\/\/bigdatatime.eu\/pdf-summarization-and-flashcard-generation-with-chatgpt\/\" target=\"_blank\" rel=\"noopener\">ChatGPT flashcard generator and document summarizer,<\/a> where the headings are used to split up a larger file into chapters. This semantically correct split of the text is important for the following steps and improves our results. Running our scraping pipeline results in the retrieval of 196 pages of course content, which are split into 528 text files that ultimately serve as our knowledge base.<\/p>\n<h2>Implementing the AI tutor<\/h2>\n<p>The core of our AI tutor is built with the <a href=\"https:\/\/python.langchain.com\/docs\/get_started\/introduction\" target=\"_blank\" rel=\"noopener\">LangChain<\/a> library, which is a framework that facilitates building applications with large language models (LLMs) like those from the GPT model family. To enable our AI tutor to effectively process and retrieve information, we need to load and prepare the data before we can make an inference that returns an answer to our questions. This pipeline follows a step-by-step process, which is as follows:<\/p>\n<ol>\n<li>Loading the documents<\/li>\n<li>Creating word embeddings<\/li>\n<li>Storing the embeddings in a vector database<\/li>\n<li>Retrieving documents with a similarity search<\/li>\n<li>Passing the retrieved documents to a LLM<\/li>\n<\/ol>\n<p>Steps 1 to 3 are only done once at the beginning, and steps 4 and 5 are repeated for every question that we ask.<\/p>\n<h3>Loading Text and Storing Vectors<\/h3>\n<p>Loading the documents is straightforward and done with LangChain&#8217;s DirectoryLoader class. Thereby, the functionality of the class basically iterates over the files in a directory and stores them in a list. The more interesting part happens when we convert the raw text documents into embeddings in the next step. Embeddings allow for the creation of a vectorized representation of text, enabling us to analyze and compare pieces of text in the vector space. This is particularly valuable for conducting semantic searches, as it allows us to identify texts that are most similar based on their vector representations. For our project, we use the OpenAIEmbeddings class also from LangChain, which serves as our access point to OpenAI&#8217;s embedding service. The last data preparation step consists of storing the embeddings in a vector database, which allows for efficient retrieval. For our project, we use <a href=\"https:\/\/engineering.fb.com\/2017\/03\/29\/data-infrastructure\/faiss-a-library-for-efficient-similarity-search\/\" target=\"_blank\" rel=\"noopener\">Faiss<\/a>, a vector database developed by Meta.<\/p>\n<h3>Querying Process and Answer Generation<\/h3>\n<p>Once our database is ready, we can input questions or queries into our AI tutoring system. Utilizing similarity search algorithms, the vector database retrieves relevant documents based on query similarities. This retrieval process enables quick access to specific sections of course material that may hold answers or explanations related to our inquiries. Upon retrieving relevant documents from our knowledge base, we can then employ a GPT model to formulate accurate answers in response to user queries. The LLM ensures that we receive high-quality and contextually relevant responses tailored specifically to our questions. For better comprehension, we will now walk through the process step by step.<\/p>\n<p>First, we set up the question, which will be &#8220;How can I share reports with Power BI?&#8221; or in German &#8220;Wie kann ich mit Power BI Berichte teilen?&#8221;. We first use this question for a similarity search in the vector database, which retrieves the following four documents:<\/p>\n<p><a href=\"https:\/\/bigdatatime.eu\/wp-content\/uploads\/2023\/10\/ai-tutor_doc-retrieval.jpg\"><img loading=\"lazy\" decoding=\"async\" class=\"aligncenter size-full wp-image-566\" src=\"https:\/\/bigdatatime.eu\/wp-content\/uploads\/2023\/10\/ai-tutor_doc-retrieval.jpg\" alt=\"\" width=\"1218\" height=\"517\" srcset=\"https:\/\/bigdatatime.eu\/wp-content\/uploads\/2023\/10\/ai-tutor_doc-retrieval.jpg 1218w, https:\/\/bigdatatime.eu\/wp-content\/uploads\/2023\/10\/ai-tutor_doc-retrieval-300x127.jpg 300w, https:\/\/bigdatatime.eu\/wp-content\/uploads\/2023\/10\/ai-tutor_doc-retrieval-1024x435.jpg 1024w, https:\/\/bigdatatime.eu\/wp-content\/uploads\/2023\/10\/ai-tutor_doc-retrieval-768x326.jpg 768w\" sizes=\"(max-width: 1218px) 100vw, 1218px\" \/><\/a><\/p>\n<p>You can see that three of the four documents are very relevant to our question about sharing reports, which means that the similarity search worked well. Here is also the proof that our initial semantically correct splitting of the documents paid off, because otherwise we would retrieve a lot of noise from the database. For example, a common strategy for this type of application if we do not have a structure to build from is to use a fuzzy approach where a large document is split at defined, overlapping word intervals. The LLM that interprets the retrieved documents can certainly handle this, but it is always better to clean the input data as much as possible to improve the accuracy and stability of the output.<\/p>\n<p>As our last step, these four documents are now passed to the GPT model with the instructions to formulate an answer to our question based on the context of the four documents. LangChain handles the prompt creation and the API call for inference, and we get the following answer to our question:<\/p>\n<p><a href=\"https:\/\/bigdatatime.eu\/wp-content\/uploads\/2023\/10\/ai-tutor_answer.jpg\"><img loading=\"lazy\" decoding=\"async\" class=\"aligncenter size-full wp-image-569\" src=\"https:\/\/bigdatatime.eu\/wp-content\/uploads\/2023\/10\/ai-tutor_answer.jpg\" alt=\"\" width=\"1218\" height=\"52\" srcset=\"https:\/\/bigdatatime.eu\/wp-content\/uploads\/2023\/10\/ai-tutor_answer.jpg 1218w, https:\/\/bigdatatime.eu\/wp-content\/uploads\/2023\/10\/ai-tutor_answer-300x13.jpg 300w, https:\/\/bigdatatime.eu\/wp-content\/uploads\/2023\/10\/ai-tutor_answer-1024x44.jpg 1024w, https:\/\/bigdatatime.eu\/wp-content\/uploads\/2023\/10\/ai-tutor_answer-768x33.jpg 768w\" sizes=\"(max-width: 1218px) 100vw, 1218px\" \/><\/a><\/p>\n<p>The answer is pretty solid and very relevant to our question. Another very useful feature is that the hallucinations of the LLM are kept to a minimum with this approach. Hallucinations are incorrect answers that the model comes up with. For example, if we ask the model, &#8220;What is a squirrel-cage rotor?&#8221; or in German, &#8220;Was ist ein Kurzschlussl\u00e4ufer?&#8221; we get the following answer:<\/p>\n<p><img loading=\"lazy\" decoding=\"async\" class=\"aligncenter size-full wp-image-571\" src=\"https:\/\/bigdatatime.eu\/wp-content\/uploads\/2023\/10\/ai-tutor_unknown.jpg\" alt=\"\" width=\"144\" height=\"34\" \/><\/p>\n<h2>Conclusion<\/h2>\n<p>The development of the specialized private AI tutor for the Microsoft Azure Power BI course introduces an innovative way of engaging with educational content. By leveraging the power of Python, web scraping techniques, and advanced libraries like LangChain and GPT models, we successfully built an intelligent tutoring system capable of providing personalized and accurate responses. The biggest advantage of this type of system is definitely the increased speed of information retrieval. We basically built a specialized search engine that dynamically compiles the search results in the most targeted and accurate fashion possible, providing a direct answer to a question.<\/p>\n<p>Overall, LangChain and similar frameworks provide a novel approach to utilizing state-of-the-art LLMs and have spawned a new wave of sophisticated AI applications. The system that we built here with a few lines of code can be leveraged in a lot of different scenarios. For example, the most recent generation of customer support chatbots are probably all running on the same or at least a similar pipeline. A knowledge base is set up with very relevant information about a company&#8217;s products or services, and customer questions are used the same way as we used for our AI tutor. The same system can also be used for company internal knowledge, interacting with user manuals, online documentation, or research papers. Although the responses are not always perfect and one should always check the source, which can be printed with the answer, it feels like we are moving into an era of real AI integration into a vast number of applications. The code for this project can be found on <a href=\"https:\/\/github.com\/marco507\/Building-a-Private-AI-Tutor\" target=\"_blank\" rel=\"noopener\">GitHub<\/a>.<\/p>\n","protected":false},"excerpt":{"rendered":"<p>In this article, we will look into one of my recent projects, which is the creation of a specialized private AI tutor for a Microsoft [&#8230;]<\/p>\n","protected":false},"author":2,"featured_media":581,"comment_status":"closed","ping_status":"open","sticky":false,"template":"","format":"standard","meta":{"footnotes":""},"categories":[6,8,1],"tags":[],"_links":{"self":[{"href":"https:\/\/bigdatatime.eu\/wp-json\/wp\/v2\/posts\/557"}],"collection":[{"href":"https:\/\/bigdatatime.eu\/wp-json\/wp\/v2\/posts"}],"about":[{"href":"https:\/\/bigdatatime.eu\/wp-json\/wp\/v2\/types\/post"}],"author":[{"embeddable":true,"href":"https:\/\/bigdatatime.eu\/wp-json\/wp\/v2\/users\/2"}],"replies":[{"embeddable":true,"href":"https:\/\/bigdatatime.eu\/wp-json\/wp\/v2\/comments?post=557"}],"version-history":[{"count":10,"href":"https:\/\/bigdatatime.eu\/wp-json\/wp\/v2\/posts\/557\/revisions"}],"predecessor-version":[{"id":583,"href":"https:\/\/bigdatatime.eu\/wp-json\/wp\/v2\/posts\/557\/revisions\/583"}],"wp:featuredmedia":[{"embeddable":true,"href":"https:\/\/bigdatatime.eu\/wp-json\/wp\/v2\/media\/581"}],"wp:attachment":[{"href":"https:\/\/bigdatatime.eu\/wp-json\/wp\/v2\/media?parent=557"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https:\/\/bigdatatime.eu\/wp-json\/wp\/v2\/categories?post=557"},{"taxonomy":"post_tag","embeddable":true,"href":"https:\/\/bigdatatime.eu\/wp-json\/wp\/v2\/tags?post=557"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}