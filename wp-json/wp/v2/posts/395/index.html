{"id":395,"date":"2023-07-14T10:14:04","date_gmt":"2023-07-14T08:14:04","guid":{"rendered":"https:\/\/bigdatatime.eu\/?p=395"},"modified":"2023-11-16T17:56:54","modified_gmt":"2023-11-16T16:56:54","slug":"emotion-detection-in-images","status":"publish","type":"post","link":"https:\/\/bigdatatime.eu\/emotion-detection-in-images\/","title":{"rendered":"Emotion Detection in Images"},"content":{"rendered":"<p>In an increasingly digital and interconnected world, understanding human emotions has become a critical aspect of various industries. Emotions significantly impact our decision-making processes, behavior, and overall experience. Marketing departments are particularly interested in leveraging emotion detection technology to gain insights into consumer preferences, optimize advertising strategies, and enhance user experiences. This project report focuses on the development and implementation of an emotion detection system capable of analyzing images to identify the underlying emotions expressed by individuals.<\/p>\n<h2>Conception<\/h2>\n<p>To solve this task, I decided to train a convolutional neural network (CNN) with a public dataset consisting of images of faces categorized into seven different emotions. To get a viable solution, the concept of transfer learning will be employed. This should result in a solution with state-of-the-art accuracy regarding the classification of emotions.<\/p>\n<h3>Basic Frameworks<\/h3>\n<p>The primary frameworks for implementing the emotion recognition solution will be TensorFlow and OpenCV. TensorFlow is an open-source library that makes it easy to train, test, and develop neural networks. The name TensorFlow stems from the use of multidimensional data (tensors) as input data sent through several intermediate layers. These layers can be individually selected to build up a neuronal network architecture. Additionally, the library also contains several pre-trained models which can be used for transfer learning. The second library, OpenCV, which is a computer vision library, features a lot of useful algorithms that will be used to extract faces and manipulate images for the inference step.<\/p>\n<h3>Transfer Learning and Model Choice<\/h3>\n<p>With transfer learning, it is possible to use an existing model to solve different but related problems to the original purpose the model was conceived for. The model\u2019s pre-trained weights are reused, and the architecture of the original model is slightly altered. Transfer learning conserves time, generally results in better performance, and shrinks the scale of necessary training data sets. The model that the emotion classifier for this project is based on is the VGG19 model. The VGG19 is thereby a deep CNN model, which means that the model consists of multiple layers, including a 1000 neurons dense output layer. This is due to the fact that VGG19 was trained to classify 1000 different categories. To fit the model for the use case of detecting emotions, the original output layers, including the 1000-neuron dense layer, will be swapped with new output layers corresponding to the number of emotions that we want to identify. Additionally, we lock the original weights of the VGG19 model and train only our modified layers on the emotion dataset.<\/p>\n<h3>Dataset Selection and Issues<\/h3>\n<p>To train the model for emotion recognition, the FER2013 dataset, which consists of around 30000 images of facial expressions, will be used. The images are thereby classified into seven different categories of emotion. The dataset also features around 3500 test images for validation of the trained model. Although the dataset features a reasonable amount of images for training, there is the problem of some categories being under and over-represented. This introduces the problem of bias, as, for example, the Happy category contains around 7000 images and the Disgust category features only around 400 images. To combat this issue, the data will be augmented, for example, by flipping, rotating, or cropping images. Here is the <a href=\"https:\/\/www.kaggle.com\/datasets\/msambare\/fer2013\">link<\/a> to the dataset.<\/p>\n<h3>Model Training and Inference<\/h3>\n<p>The overall process of implementing the solution for emotion recognition can be split up into two distinct parts, the model creation, and the inference part. The model creation procedure consists thereby of augmenting the dataset, setting up the training environment and architecture with TensorFlow, and then starting the training process.<\/p>\n<p><img loading=\"lazy\" decoding=\"async\" class=\"aligncenter size-full wp-image-396\" src=\"https:\/\/bigdatatime.eu\/wp-content\/uploads\/2023\/07\/emotion-detection_training.jpg\" alt=\"\" width=\"853\" height=\"155\" srcset=\"https:\/\/bigdatatime.eu\/wp-content\/uploads\/2023\/07\/emotion-detection_training.jpg 853w, https:\/\/bigdatatime.eu\/wp-content\/uploads\/2023\/07\/emotion-detection_training-300x55.jpg 300w, https:\/\/bigdatatime.eu\/wp-content\/uploads\/2023\/07\/emotion-detection_training-768x140.jpg 768w\" sizes=\"(max-width: 853px) 100vw, 853px\" \/><\/p>\n<p>The second step, which presents the actual solution for making a prediction, consists of the trained model, which is loaded into a Jupyter Notebook for inference. The process of inference consists thereby of loading an image into a Jupyter Notebook, extracting the face with OpenCV, preprocessing the image, and passing the image to the trained model for prediction. The prediction is visualized as the image with the classified emotion written on it.<\/p>\n<p><img loading=\"lazy\" decoding=\"async\" class=\"aligncenter size-full wp-image-397\" src=\"https:\/\/bigdatatime.eu\/wp-content\/uploads\/2023\/07\/emotion-detection_inference.jpg\" alt=\"\" width=\"842\" height=\"140\" srcset=\"https:\/\/bigdatatime.eu\/wp-content\/uploads\/2023\/07\/emotion-detection_inference.jpg 842w, https:\/\/bigdatatime.eu\/wp-content\/uploads\/2023\/07\/emotion-detection_inference-300x50.jpg 300w, https:\/\/bigdatatime.eu\/wp-content\/uploads\/2023\/07\/emotion-detection_inference-768x128.jpg 768w\" sizes=\"(max-width: 842px) 100vw, 842px\" \/><\/p>\n<h2>Development<\/h2>\n<p>After creating a concept, the next step was to start the Implementation. This <a href=\"https:\/\/bigdatatime.eu\/wp-content\/uploads\/2023\/07\/emotion-detection_development.pdf\" target=\"_blank\" rel=\"noopener\">PDF<\/a> explains the development process in detail.<\/p>\n<h2>Conclusion<\/h2>\n<p>Looking back on the creation of the emotion classifier, I can say that this project was a very pleasant and rewarding learning experience, regarding computer vision and the development workflow of deep learning models. Given the issues regarding data quality, bias-variance problems during training, hardware limitations, and the trial and error of hyperparameter tuning, the task also proved to be more difficult than initially thought. As the saying goes, the devil lies in the detail, and I can now understand why training deep learning models is by a lot of machine learning practitioners considered a mixture of art and science.<\/p>\n<p>Personally, I am satisfied with the final result, although I wished for a bit higher accuracy and more emotions. To improve upon this work, a better dataset like AffectNet which has around one million images could be used to train a model on better hardware like TPUs. Grid-search for finding the best parameters and model structure could also be used to get an overall better performance. The code for this project can be found in this <a href=\"https:\/\/github.com\/marco507\/Emotion-Classifier\">repository.<\/a><\/p>\n","protected":false},"excerpt":{"rendered":"<p>In an increasingly digital and interconnected world, understanding human emotions has become a critical aspect of various industries. Emotions significantly impact our decision-making processes, behavior, [&#8230;]<\/p>\n","protected":false},"author":2,"featured_media":401,"comment_status":"closed","ping_status":"open","sticky":false,"template":"","format":"standard","meta":{"footnotes":""},"categories":[7,1],"tags":[],"_links":{"self":[{"href":"https:\/\/bigdatatime.eu\/wp-json\/wp\/v2\/posts\/395"}],"collection":[{"href":"https:\/\/bigdatatime.eu\/wp-json\/wp\/v2\/posts"}],"about":[{"href":"https:\/\/bigdatatime.eu\/wp-json\/wp\/v2\/types\/post"}],"author":[{"embeddable":true,"href":"https:\/\/bigdatatime.eu\/wp-json\/wp\/v2\/users\/2"}],"replies":[{"embeddable":true,"href":"https:\/\/bigdatatime.eu\/wp-json\/wp\/v2\/comments?post=395"}],"version-history":[{"count":8,"href":"https:\/\/bigdatatime.eu\/wp-json\/wp\/v2\/posts\/395\/revisions"}],"predecessor-version":[{"id":692,"href":"https:\/\/bigdatatime.eu\/wp-json\/wp\/v2\/posts\/395\/revisions\/692"}],"wp:featuredmedia":[{"embeddable":true,"href":"https:\/\/bigdatatime.eu\/wp-json\/wp\/v2\/media\/401"}],"wp:attachment":[{"href":"https:\/\/bigdatatime.eu\/wp-json\/wp\/v2\/media?parent=395"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https:\/\/bigdatatime.eu\/wp-json\/wp\/v2\/categories?post=395"},{"taxonomy":"post_tag","embeddable":true,"href":"https:\/\/bigdatatime.eu\/wp-json\/wp\/v2\/tags?post=395"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}